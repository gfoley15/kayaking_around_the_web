{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc953f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter, BeautifulSoup and dependencies\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pymongo import MongoClient\n",
    "from splinter import Browser\n",
    "import time\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5c10fe8-402d-471f-9a84-36bf3ff11785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of MongoClient\n",
    "mongo = MongoClient(port=27017)\n",
    "\n",
    "# assign the met database to a variable name\n",
    "db = mongo['kayak']\n",
    "\n",
    "# assign the collection to a variable\n",
    "flight_search = db['flight_search']\n",
    "\n",
    "# assign the met database to a variable name\n",
    "dbtwo = mongo['kayak']\n",
    "\n",
    "# assign the collection to a variable\n",
    "airports = dbtwo['airports']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e423ecdb-03fb-4870-b174-92ebbcf2e6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flight_search.delete_many({}) #empty the collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4192850-49f6-406b-9844-500cc047df64",
   "metadata": {},
   "source": [
    "# Airport Code Web Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27e70df6-442c-4150-87a2-6e8fa758df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch browser\n",
    "browser = Browser('chrome')\n",
    "time.sleep(2)\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_busiest_airports_by_passenger_traffic\"\n",
    "browser.visit(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce61dc29-e13b-43ab-a2a8-845c19300e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Beautiful Soup\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "table = soup.find('table', class_='wikitable sortable jquery-tablesorter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03b70de9-5702-49f2-a091-0b189f9c30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list\n",
    "airports = []\n",
    "rows = table.find_all('tr', class_=False)\n",
    "# Loop through the scraped data to create a list of rows\n",
    "for row in rows:\n",
    "    row_data_id = row.find_all('td')\n",
    "    row = [row.text for row in row_data_id]  \n",
    "    airports.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "234fc4ea-0859-4a9e-b157-edf76fc0ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create airports dataframe\n",
    "airports_df = pd.DataFrame(airports, \n",
    "                           columns = [\"Rank\",\n",
    "                                      \"Airport\",\n",
    "                                      \"Location\",\n",
    "                                      \"Country\",\n",
    "                                      \"A/P Code\",\n",
    "                                      \"Total Passengers\",\n",
    "                                      \"Rank Change\",\n",
    "                                      \"Rank pct change\"\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bed5aad7-d518-4b2e-80c2-f0406e94e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary fields\n",
    "airports_df = airports_df.drop(columns=[\"Rank Change\", \"Rank pct change\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc62bd9b-96ac-46ee-9d5d-ec1810609fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop blank values\n",
    "airports_df = airports_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6958825b-2542-4f4a-9840-ede799a92575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the airport code from the A/P Code.\n",
    "airports_df[['IATA', 'ICAO Code']] = airports_df['A/P Code'].str.split('/', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b2cc622-890e-4887-93d1-8278e6295525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export for collaboration purposes\n",
    "airports_df.to_csv('../Output/airports_df.csv',index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f900c86-df43-46ea-a6f4-c20b9f591e12",
   "metadata": {},
   "source": [
    "# Kayak.com Web Scrape For Airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a30454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete loop for destination airports and kayak flights\n",
    "airport_codes = airports_df['IATA'].tolist()\n",
    "departure = 'MCI' \n",
    "\n",
    "from_date = input(\"Enter departure date (YYYY-MM-DD): \")\n",
    "to_date = input(\"Enter return date (YYYY-MM-DD): \")\n",
    "\n",
    "browser = Browser('chrome')\n",
    "trip_data = []\n",
    "\n",
    "# Loop through each airport code\n",
    "for airport in airport_codes[40]:\n",
    "    destination = airport\n",
    "    url = f\"https://www.kayak.com/flights/{departure}-{destination}/{from_date}/{to_date}\"\n",
    "    browser.visit(url)\n",
    "    time.sleep(5)\n",
    "    print(url)\n",
    "    \n",
    "    # Create a Beautiful Soup object\n",
    "    soup = bs(browser.html,'html.parser')\n",
    "\n",
    "    # Loop through HTML code and extract key metadata\n",
    "    for trip_id, i in enumerate(soup.find_all(id=\"listWrapper\")[0].find_all('div', class_=\"nrc6 nrc6-mod-pres-multi-fare\")):\n",
    "        trip = {\n",
    "            \"trip_id\": trip_id,\n",
    "            \"outbound_date\": from_date,\n",
    "            \"return_date\": to_date,\n",
    "            \"outbound_departure_time\": \"\",\n",
    "            \"outbound_arrival_time\": \"\",\n",
    "            \"outbound_flight_duration\": \"\",\n",
    "            \"outbound_route\": \"\",\n",
    "            \"outbound_airline\": \"\",\n",
    "            \"return_departure_time\": \"\",\n",
    "            \"return_arrival_time\": \"\",\n",
    "            \"return_flight_duration\": \"\",\n",
    "            \"return_route\": \"\",\n",
    "            \"return_airline\": \"\",\n",
    "            \"price\": \"\",\n",
    "            \"tier\": \"\"\n",
    "        }\n",
    "        \n",
    "        # Extract outbound flight data\n",
    "        outbound_flight_info = i.find_all('div', class_='VY2U')[0]\n",
    "        outbound_flight_times = outbound_flight_info.find_all('span')\n",
    "        trip[\"outbound_departure_time\"] = outbound_flight_times[0].text.strip()\n",
    "        trip[\"outbound_arrival_time\"] = outbound_flight_times[2].text.strip()\n",
    "        outbound_airline_name = outbound_flight_info.find('div', class_='c_cgF c_cgF-mod-variant-default')\n",
    "        trip[\"outbound_airline\"] = outbound_airline_name.text.strip()\n",
    "        trip[\"outbound_flight_duration\"] = i.find('div', class_='xdW8').find('div', class_='vmXl vmXl-mod-variant-default').text.strip()\n",
    "        trip[\"outbound_route\"] = i.find('div', class_='xdW8').find('div', class_='EFvI').text.strip()\n",
    "        \n",
    "        # Extract return flight data\n",
    "        return_flight_info = i.find_all('div', class_='VY2U')[1]\n",
    "        return_flight_times = return_flight_info.find_all('span')\n",
    "        trip[\"return_departure_time\"] = return_flight_times[0].text.strip()\n",
    "        trip[\"return_arrival_time\"] = return_flight_times[2].text.strip()\n",
    "        return_airline_name = return_flight_info.find('div', class_='c_cgF c_cgF-mod-variant-default')\n",
    "        trip[\"return_airline\"] = return_airline_name.text.strip()\n",
    "        trip[\"return_flight_duration\"] = i.find_all('div', class_='xdW8')[1].find('div', class_='vmXl vmXl-mod-variant-default').text.strip()\n",
    "        trip[\"return_route\"] = i.find_all('div', class_='xdW8')[1].find('div', class_='EFvI').text.strip()\n",
    "        \n",
    "        # Extract price and tier\n",
    "        trip[\"price\"] = i.find('div', class_=\"f8F1-price-text\").text.strip()\n",
    "        trip[\"tier\"] = i.find('div', class_=\"aC3z-name aC3z-mod-ellipsis\").text.strip()\n",
    "\n",
    "        # Append HTML elements into trip_data list\n",
    "        trip_data.append(trip)\n",
    "        time.sleep(5)\n",
    "\n",
    "# Insert all trip data into flight search Mondo DB\n",
    "flight_search.insert_many(trip_data)\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3e2e8f-2b39-4a15-8871-c0ff7f175d27",
   "metadata": {},
   "source": [
    "# Testing: Kayak Web Scrapping and HTML Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf11a2-11b1-46af-8444-66458fcef7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kayak URL testing\n",
    "airport_codes = airport_codes_df['IATA'].tolist()\n",
    "departure = 'MCI' \n",
    "\n",
    "from_date = input(\"Enter departure date (YYYY-MM-DD): \")\n",
    "to_date = input(\"Enter return date (YYYY-MM-DD): \")\n",
    "\n",
    "# Loop through each airport code\n",
    "for airport in airport_codes:\n",
    "    destination = airport\n",
    "    url = f\"https://www.kayak.com/flights/{departure}-{destination}/{from_date}/{to_date}\"\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9069fa-30db-4930-8136-02afde7d4f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single URL test for web scraping elements\n",
    "browser = Browser('chrome')\n",
    "browser.visit('https://www.kayak.com/flights/MCI-SAN/2024-07-04/2024-07-11')\n",
    "time.sleep(5)\n",
    "# Create a Beautiful Soup object\n",
    "soup = bs(browser.html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af2d5da-8b3f-4a26-8594-234d74b840dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single URL test\n",
    "# Find all flight text elements in HTML\n",
    "for i in soup.find_all(id=\"listWrapper\")[0].find_all('div', class_ = \"nrc6 nrc6-mod-pres-multi-fare\"):\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d06c4f1-5f1c-4ce4-95b7-7f01591fcfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single URL test\n",
    "# Find flight times in HTML\n",
    "flight_times_list = []\n",
    "\n",
    "for flight in soup.find_all('div', class_='VY2U'):  \n",
    "    flight_times = flight.find_all('span')  \n",
    "    departure_time = flight_times[0].text.strip()  \n",
    "    arrival_time = flight_times[2].text.strip() \n",
    "    airline_name = flight.find('div', class_='c_cgF c_cgF-mod-variant-default').text.strip()\n",
    "\n",
    "    flight_times_list.append({\n",
    "        \"departure_time\": departure_time,\n",
    "        \"arrival_time\": arrival_time,\n",
    "        \"airline\": airline_name\n",
    "    })\n",
    "\n",
    "print(flight_times_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06ffc86-f96a-4394-8d74-f19e50577384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single URL test\n",
    "# Find flight durations in HTML\n",
    "flight_durations_list = []\n",
    "\n",
    "for i in soup.find_all(id=\"listWrapper\")[0].find_all('div', class_=\"nrc6 nrc6-mod-pres-multi-fare\"):\n",
    "    duration_route = i.find_all('div', class_='xdW8')\n",
    "    outbound_flight_duration = duration_route[0].find('div', class_='vmXl vmXl-mod-variant-default').text.strip()\n",
    "    return_flight_duration = duration_route[1].find('div', class_='vmXl vmXl-mod-variant-default').text.strip()\n",
    "    flight_durations_list.append({\n",
    "        \"outbound_flight_duration\": outbound_flight_duration,\n",
    "        \"return_flight_duration\": return_flight_duration\n",
    "    })\n",
    "\n",
    "print(flight_durations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d255cf38-8b0a-4686-b59e-91ef2f31e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single URL test\n",
    "# Find flight routes in HTML\n",
    "flight_routes_list = []\n",
    "\n",
    "for i in soup.find_all(id=\"listWrapper\")[0].find_all('div', class_=\"nrc6 nrc6-mod-pres-multi-fare\"):\n",
    "    duration_route = i.find_all('div', class_='xdW8')\n",
    "    outbound_route = duration_route[0].find('div', class_='EFvI').text.strip()\n",
    "    return_route = duration_route[1].find('div', class_='EFvI').text.strip()\n",
    "    flight_routes_list.append({\n",
    "        \"outbound_route\": outbound_route,\n",
    "        \"return_route\": return_route\n",
    "    })\n",
    "print(flight_routes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b50763-17b9-40c5-9b2d-02c2eac8552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single URL test\n",
    "# Find price information in HTML\n",
    "price_list = []\n",
    "\n",
    "for i in soup.find_all(id=\"listWrapper\")[0].find_all('div', class_=\"nrc6 nrc6-mod-pres-multi-fare\"):\n",
    "    # Extract all price text elements\n",
    "    price_texts = i.find_all('div', class_=\"f8F1-price-text\")\n",
    "    \n",
    "    for price_text in price_texts:\n",
    "        price = price_text.text.strip()\n",
    "        price_list.append(price)\n",
    "\n",
    "print(price_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb7c08-b6db-4a4c-b8c3-ac102158b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single URL test\n",
    "# Find tier information in HTML\n",
    "tier_list = []\n",
    "\n",
    "for i in soup.find_all(id=\"listWrapper\")[0].find_all('div', class_=\"nrc6 nrc6-mod-pres-multi-fare\"):\n",
    "    # Extract all price text elements\n",
    "    tier_texts = i.find_all('div', class_=\"aC3z-name aC3z-mod-ellipsis\")\n",
    "    \n",
    "    for tier_text in tier_texts:\n",
    "        tier = tier_text.text.strip()\n",
    "        tier_list.append(tier)\n",
    "\n",
    "print(tier_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad24fa0-7577-46fb-acd6-50f4752fd0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single URL test\n",
    "# Combine all text elements into one for loop\n",
    "flight_data = {\n",
    "    \"flight_times\": [],\n",
    "    \"flight_durations\": [],\n",
    "    \"flight_routes\": [],\n",
    "    \"prices\": [],\n",
    "    \"tiers\": []\n",
    "}\n",
    "\n",
    "for i in soup.find_all(id=\"listWrapper\")[0].find_all('div', class_=\"nrc6 nrc6-mod-pres-multi-fare\"):\n",
    "    for flight in soup.find_all('div', class_='VY2U'):  \n",
    "        flight_times = flight.find_all('span')  \n",
    "        departure_time = flight_times[0].text.strip()  \n",
    "        arrival_time = flight_times[2].text.strip() \n",
    "        airline_name = flight.find('div', class_='c_cgF c_cgF-mod-variant-default')\n",
    "        airline = airline_name.text.strip()\n",
    "        flight_data[\"flight_times\"].append({\n",
    "            \"departure_time\": departure_time,\n",
    "            \"arrival_time\": arrival_time,\n",
    "            \"airline\": airline\n",
    "        })\n",
    "        \n",
    "    duration_route = i.find_all('div', class_='xdW8')\n",
    "    for dr in duration_route:\n",
    "        outbound_flight_duration = duration_route[0].find('div', class_='vmXl vmXl-mod-variant-default').text.strip()\n",
    "        return_flight_duration = duration_route[1].find('div', class_='vmXl vmXl-mod-variant-default').text.strip()\n",
    "        flight_data[\"flight_durations\"].append({\n",
    "            \"outbound_flight_duration\": outbound_flight_duration,\n",
    "            \"return_flight_duration\": return_flight_duration\n",
    "        })\n",
    "\n",
    "        outbound_route = duration_route[0].find('div', class_='EFvI').text.strip()\n",
    "        return_route = duration_route[1].find('div', class_='EFvI').text.strip()\n",
    "        flight_data[\"flight_routes\"].append({\n",
    "            \"outbound_route\": outbound_route,\n",
    "            \"return_route\": return_route\n",
    "        })\n",
    "    \n",
    "    # Extract all price text elements\n",
    "    price_texts = i.find_all('div', class_=\"f8F1-price-text\")\n",
    "    \n",
    "    for price_text in price_texts:\n",
    "        price = price_text.text.strip()\n",
    "        flight_data[\"prices\"].append(price)\n",
    "\n",
    "    tier_texts = i.find_all('div', class_=\"aC3z-name aC3z-mod-ellipsis\")\n",
    "    \n",
    "    for tier_text in tier_texts:\n",
    "        tier = tier_text.text.strip()\n",
    "        flight_data[\"tiers\"].append(tier)\n",
    "\n",
    "pprint(flight_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf7bdc6-64c1-441b-bf5c-e07b8b1f4a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single URL test\n",
    "# Combine all text elements using one for loop and placing records into a list\n",
    "single_url_scrape = []\n",
    "\n",
    "for trip_id, i in enumerate(soup.find_all(id=\"listWrapper\")[0].find_all('div', class_=\"nrc6 nrc6-mod-pres-multi-fare\")):\n",
    "    trip = {\n",
    "        \"trip_id\": trip_id,\n",
    "        \"outbound_departure_time\": \"\",\n",
    "        \"outbound_arrival_time\": \"\",\n",
    "        \"outbound_flight_duration\": \"\",\n",
    "        \"outbound_route\": \"\",\n",
    "        \"outbound_airline\": \"\",\n",
    "        \"return_departure_time\": \"\",\n",
    "        \"return_arrival_time\": \"\",\n",
    "        \"return_flight_duration\": \"\",\n",
    "        \"return_route\": \"\",\n",
    "        \"return_airline\": \"\",\n",
    "        \"price\": \"\",\n",
    "        \"tier\": \"\"\n",
    "    }\n",
    "    \n",
    "    # Extract outbound flight data\n",
    "    outbound_flight_info = i.find_all('div', class_='VY2U')[0]\n",
    "    outbound_flight_times = outbound_flight_info.find_all('span')\n",
    "    trip[\"outbound_departure_time\"] = outbound_flight_times[0].text.strip()\n",
    "    trip[\"outbound_arrival_time\"] = outbound_flight_times[2].text.strip()\n",
    "    outbound_airline_name = outbound_flight_info.find('div', class_='c_cgF c_cgF-mod-variant-default')\n",
    "    trip[\"outbound_airline\"] = outbound_airline_name.text.strip()\n",
    "    trip[\"outbound_flight_duration\"] = i.find('div', class_='xdW8').find('div', class_='vmXl vmXl-mod-variant-default').text.strip()\n",
    "    trip[\"outbound_route\"] = i.find('div', class_='xdW8').find('div', class_='EFvI').text.strip()\n",
    "    \n",
    "    # Extract return flight data\n",
    "    return_flight_info = i.find_all('div', class_='VY2U')[1]\n",
    "    return_flight_times = return_flight_info.find_all('span')\n",
    "    trip[\"return_departure_time\"] = return_flight_times[0].text.strip()\n",
    "    trip[\"return_arrival_time\"] = return_flight_times[2].text.strip()\n",
    "    return_airline_name = return_flight_info.find('div', class_='c_cgF c_cgF-mod-variant-default')\n",
    "    trip[\"return_airline\"] = return_airline_name.text.strip()\n",
    "    trip[\"return_flight_duration\"] = i.find_all('div', class_='xdW8')[1].find('div', class_='vmXl vmXl-mod-variant-default').text.strip()\n",
    "    trip[\"return_route\"] = i.find_all('div', class_='xdW8')[1].find('div', class_='EFvI').text.strip()\n",
    "    \n",
    "    # Extract price and tier\n",
    "    trip[\"price\"] = i.find('div', class_=\"f8F1-price-text\").text.strip()\n",
    "    trip[\"tier\"] = i.find('div', class_=\"aC3z-name aC3z-mod-ellipsis\").text.strip()\n",
    "    \n",
    "    single_url_scrape.append(trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f1767-ca1f-4d64-828c-2ef9cb2560ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single URL test\n",
    "kayak_df = pd.DataFrame(single_url_scrape)\n",
    "kayak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb130a10-8e50-4bb4-96d4-c88c319f07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single URL test\n",
    "# Extract all flight text elements\n",
    "for i in soup.find_all(id=\"listWrapper\")[0].find_all('div', class_ = \"M_JD-large-display\"):\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c1c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single URL test\n",
    "# Extract booking URL\n",
    "for i in soup.find_all(id=\"listWrapper\")[0].find_all('div', class_=\"nrc6 nrc6-mod-pres-multi-fare\"):\n",
    "        booking_link_tag = i.find(\"a\")\n",
    "kayak_url = 'https://kayak.com'\n",
    "flight_booking_url =\n",
    "booking_link = {kayak_url}\n",
    "print(booking_link_tag['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9279527a-2196-4f18-9ead-99f50bc8623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
